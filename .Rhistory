predictions <- predict(model_7, newdata = broward_test, type = "response")
predicted_labels <- ifelse(predictions > 0.5, 1, 0)
# Calculate confusion matrix
conf_matrix_iteration <- table(Actual = broward_test$two_year_recid, Predicted = predicted_labels)
# Update overall confusion matrix
conf_matrix7 <- conf_matrix7 + conf_matrix_iteration
# Store model & results
model_results[[i]] <- list(model = model_7, accuracy = mean(predicted_labels == broward_test$two_year_recid))
}
# Extract relevant information from the results
accuracies_7 <- sapply(model_results, function(x) x$accuracy)
# Print the summary of the accuracies
cat("Mean Testing Accuracy:", mean(accuracies_7), "\n")
cat("Standard Deviation of Testing Accuracy:", sd(accuracies), "\n")
cat("Standard Deviation of Testing Accuracy:", sd(accuracies_7), "\n")
#create dataframe of classification accuracies using confusion matrix
conf_matrix7
precision_df <- data.frame(
Classification = c("Actually No", "Actually Yes"),
Predicted_No = c(622216, 298801),
Predicted_Yes = c(170569, 351414)
)
precision_table <- precision_df |>
gt() |>
tab_spanner(
label = "7 Feature Classifier Prediction",
columns = c("Predicted_No", "Predicted_Yes")
) |>
fmt_number(
columns = vars(Predicted_No, Predicted_Yes),
decimals = 0) |>
tab_header(
title = "7 Feature Classifier Prediction of Recidivism vs Actual Recidivism",
subtitle = "Results from training 1000 times on defendant data (with 67.47% overall precision)",
)
precision_table
seven_form <- as.formula("two_year_recid ~ age + sex + juv_misd_count + juv_fel_count + priors_count + charge_id + charge_degree")
seven_model <- glm(seven_form, data = broward_train, family = binomial)
tidy_summary <- tidy(seven_model)
seven_feat_table <- tidy_summary |>
gt() |>
tab_header(
title = "Seven Feture Logistic Regression Model Summary",
subtitle = "Predictors of Recidivism"
) %>%
fmt_number(
columns = vars(estimate, std.error, statistic, p.value),
decimals = 3
) %>%
fmt_number(
columns = vars(estimate),
suffixing = TRUE
) %>%
fmt_number(
columns = vars(p.value),
decimals = 4
) %>%
tab_spanner(
label = "Coefficient",
columns = vars(estimate, std.error)
) %>%
tab_spanner(
label = "Statistical Significance",
columns = vars(statistic, p.value)
)
#This is our logistic regression model we use to train the data
seven_feat_table
tidy_summary <- tidy(seven_model)
tidy_summary
set.seed(438)
model_results <- list()
conf_matrix2 <- matrix(0, nrow = 2, ncol = 2)
# train 1000 times on 80/20 test/train split
for (i in 1:1000) {
# Split the data into training and testing sets
broward_split <- rsample::initial_split(broward_clean, prop = 0.8)
broward_train <- training(broward_split)
broward_test <- testing(broward_split)
# Define 7 feature logistic regression formula
form_2 <- as.formula("two_year_recid ~ age + priors_count")
model_2 <- glm(form_2, data = broward_train, family = binomial)
# Run model on test data
predictions <- predict(model_2, newdata = broward_test, type = "response")
predicted_labels <- ifelse(predictions > 0.5, 1, 0)
# Calculate confusion matrix
conf_matrix_iteration <- table(Actual = broward_test$two_year_recid, Predicted = predicted_labels)
# Update overall confusion matrix
conf_matrix2 <- conf_matrix + conf_matrix_iteration
# Store model & results
model_results[[i]] <- list(model = model_2, accuracy = mean(predicted_labels == broward_test$two_year_recid))
}
set.seed(438)
model_results <- list()
conf_matrix2 <- matrix(0, nrow = 2, ncol = 2)
# train 1000 times on 80/20 test/train split
for (i in 1:1000) {
# Split the data into training and testing sets
broward_split <- rsample::initial_split(broward_clean, prop = 0.8)
broward_train <- training(broward_split)
broward_test <- testing(broward_split)
# Define 7 feature logistic regression formula
form_2 <- as.formula("two_year_recid ~ age + priors_count")
model_2 <- glm(form_2, data = broward_train, family = binomial)
# Run model on test data
predictions <- predict(model_2, newdata = broward_test, type = "response")
predicted_labels <- ifelse(predictions > 0.5, 1, 0)
# Calculate confusion matrix
conf_matrix_iteration <- table(Actual = broward_test$two_year_recid, Predicted = predicted_labels)
# Update overall confusion matrix
conf_matrix2 <- conf_matrix2 + conf_matrix_iteration
# Store model & results
model_results[[i]] <- list(model = model_2, accuracy = mean(predicted_labels == broward_test$two_year_recid))
}
# Extract relevant information from the results
accuracies_2 <- sapply(model_results, function(x) x$accuracy)
# Print the summary of the accuracies
cat("Mean Testing Accuracy:", mean(accuracies_2), "\n")
cat("Standard Deviation of Testing Accuracy:", sd(accuracies_2), "\n")
#create dataframe of classification accuracies using confusion matrix
conf_matrix2
precision_df2 <- data.frame(
Classification = c("Actually No", "Actually Yes"),
Predicted_No = c(639492, 311872),
Predicted_Yes = c(153293, 338343)
)
precision_table2 <- precision_df2 |>
gt() |>
tab_spanner(
label = "2 Feature Classifier Prediction",
columns = c("Predicted_No", "Predicted_Yes")
) |>
fmt_number(
columns = vars(Predicted_No, Predicted_Yes),
decimals = 0) |>
tab_header(
title = "2 Feature (Age & Priotr Count) Classifier Prediction of Recidivism vs Actual Recidivism",
subtitle = "Results from training 1000 times on defendant data (with 67.8% overall precision)",
)
precision_table2
precision_table
precision_table2
precision_table
precision_table2
precision_table2 <- precision_df2 |>
gt() |>
tab_spanner(
label = "2 Feature Classifier Prediction",
columns = c("Predicted_No", "Predicted_Yes")
) |>
fmt_number(
columns = vars(Predicted_No, Predicted_Yes),
decimals = 0) |>
tab_header(
title = "2 Feature (Age & Prior Count) Classifier Prediction of Recidivism vs Actual Recidivism",
subtitle = "Results from training 1000 times on defendant data (with 67.8% overall precision)",
)
precision_table2
precision_table
precision_table2 <- precision_df2 |>
gt() |>
tab_spanner(
label = "2 Feature Classifier Prediction",
columns = c("Predicted_No", "Predicted_Yes")
) |>
fmt_number(
columns = vars(Predicted_No, Predicted_Yes),
decimals = 0) |>
tab_header(
title = "2 Feature (Age & Prior Count) Classifier Prediction of Recidivism vs Actual Recidivism",
subtitle = "Results from training 1000 times on defendant data with features age & prior count: 67.8% overall precision)",
)
precision_table2
precision_table2 <- precision_df2 |>
gt() |>
tab_spanner(
label = "2 Feature Classifier Prediction",
columns = c("Predicted_No", "Predicted_Yes")
) |>
fmt_number(
columns = vars(Predicted_No, Predicted_Yes),
decimals = 0) |>
tab_header(
title = "2 Feature (Age & Prior Count) Classifier Prediction of Recidivism vs Actual Recidivism",
subtitle = "Results from training 1000 times on defendant data with features age & prior count:
67.8% overall precision",
)
precision_table2
precision_table2 <- precision_df2 |>
gt() |>
tab_spanner(
label = "2 Feature Classifier Prediction",
columns = c("Predicted_No", "Predicted_Yes")
) |>
fmt_number(
columns = vars(Predicted_No, Predicted_Yes),
decimals = 0) |>
tab_header(
title = "2 Feature Classifier Prediction of Recidivism vs Actual Recidivism",
subtitle = "Results from training 1000 times on defendant data with features age & prior count:
67.8% overall precision",
)
precision_table2
precision_table <- precision_df |>
gt() |>
tab_spanner(
label = "7 Feature Classifier Prediction",
columns = c("Predicted_No", "Predicted_Yes")
) |>
fmt_number(
columns = vars(Predicted_No, Predicted_Yes),
decimals = 0) |>
tab_header(
title = "7 Feature Classifier Prediction of Recidivism vs Actual Recidivism",
subtitle = "Results from training 1000 times on defendant data with features age, sex juvenile misdemeanor count, juvenile felony count, priors count, charge type, & charge degree: 67.47% overall precision",
)
precision_table
seven_form <- as.formula("two_year_recid ~ age + sex + juv_misd_count + juv_fel_count + priors_count + charge_id + charge_degree")
seven_model <- glm(seven_form, data = broward_train, family = binomial)
tidy_summary <- tidy(seven_model)
seven_feat_table <- tidy_summary |>
gt() |>
tab_header(
title = "Seven Feture Logistic Regression Model Summary",
subtitle = "Predictors of Recidivism"
) %>%
fmt_number(
columns = vars(estimate, std.error, statistic, p.value),
decimals = 3
) %>%
fmt_number(
columns = vars(estimate),
suffixing = TRUE
) %>%
fmt_number(
columns = vars(p.value),
decimals = 4
) %>%
tab_spanner(
label = "Coefficient",
columns = vars(estimate, std.error)
) %>%
tab_spanner(
label = "Statistical Significance",
columns = vars(statistic, p.value)
)
#This is our logistic regression model we use to train the data
seven_feat_table
#------------Our 2 feature logit regression model coefficent table----------------GAbi
two_form <- as.formula("two_year_recid ~ age + priors_count")
two_model <- glm(two_form, data = broward_train, family = binomial)
tidy_summary <- tidy(two_model)
tidy_summary
two_feat_table <- tidy_summary |>
gt() |>
tab_header(
title = "Two Feature Logistic Regression Model Summary",
subtitle = "Predictors of Recidivism"
) %>%
fmt_number(
columns = vars(estimate, std.error, statistic, p.value),
decimals = 3
) %>%
fmt_number(
columns = vars(estimate),
suffixing = TRUE
) %>%
fmt_number(
columns = vars(p.value),
decimals = 4
) %>%
tab_spanner(
label = "Coefficient",
columns = vars(estimate, std.error)
) %>%
tab_spanner(
label = "Statistical Significance",
columns = vars(statistic, p.value)
)
#This is our logistic regression model we use to train the data
two_feat_table
#This is our logistic regression model we use to train the data
seven_feat_table
#This is our 2 feature logistic regression model we use to train the data
two_feat_table
broward_clean <- read_csv("allData/BROWARD_CLEAN.csv")
broward_clean <- broward_clean |>
rename(charge_degree = `charge_degree (misd/fel)`) |>
mutate(sex = ifelse(sex == 0, 'male', 'female')) |>
mutate(race = as.factor(case_when(
race == 1 ~ "White",
race == 2 ~ "Black",
race == 3 ~ "Hispanic",
race == 4 ~ "Asian",
race == 5 ~ "Native American",
race == 6 ~ "Other"
)))
broward_clean
broward_clean
broward_clean
blk_broward <- broward_clean |>
filter(race == "Black")
blk_broward
set.seed(438)
blk_results <- list()
blk_broward <- broward_clean |>
filter(race == "Black")
# train 1000 times on 80/20 test/train split
for (i in 1:1000) {
# Split the data into training and testing sets
blk_split <- rsample::initial_split(blk_broward, prop = 0.8)
blk_train <- training(blk_split)
blk_test <- testing(blk_split)
# Define 7 feature logistic regression formula with only black defendants
blk_form <- as.formula("two_year_recid ~ age + sex + juv_misd_count + juv_fel_count + priors_count + charge_id + charge_degree")
blk_model <- glm(blk_form, data = blk_train, family = binomial)
# Run model on test data
predictions <- predict(blk_model, newdata = blk_test, type = "response")
predicted_labels <- ifelse(predictions > 0.5, 1, 0)
# Store model & results
blk_results[[i]] <- list(model = blk_model, accuracy = mean(predicted_labels == blk_test$two_year_recid))
}
# Extract relevant information from the results
blk_accuracies <- sapply(model_results, function(x) x$accuracy)
cat("Mean Testing Accuracy:", mean(blk_accuracies), "\n")
cat("Standard Deviation of Testing Accuracy:", sd(blk_accuracies), "\n")
wht_results <- list()
wht_broward <- broward_clean |>
filter(race == "White")
wht_broward
# Extract relevant information from the results
blk_accuracies <- sapply(blk_results, function(x) x$accuracy)
cat("Mean Testing Accuracy (Black, 7 Features):", mean(blk_accuracies), "\n")
cat("Standard Deviation of Testing Accuracy:", sd(blk_accuracies), "\n")
wht_results <- list()
wht_broward <- broward_clean |>
filter(race == "White")
# train 1000 times on 80/20 test/train split
for (i in 1:1000) {
# Split the data into training and testing sets
wht_split <- rsample::initial_split(wht_broward, prop = 0.8)
wht_train <- training(wht_split)
wht_test <- testing(wht_split)
# Define 7 feature logistic regression formula with only black defendants
wht_form <- as.formula("two_year_recid ~ age + sex + juv_misd_count + juv_fel_count + priors_count + charge_id + charge_degree")
wht_model <- glm(wht_form, data = wht_train, family = binomial)
# Run model on test data
predictions <- predict(wht_model, newdata = wht_test, type = "response")
predicted_labels <- ifelse(predictions > 0.5, 1, 0)
# Store model & results
wht_results[[i]] <- list(model = wht_model, accuracy = mean(predicted_labels == wht_test$two_year_recid))
}
# Extract relevant information from the results
wht_accuracies <- sapply(wht_results, function(x) x$accuracy)
# Print the summary of the accuracies
cat("Mean Testing Accuracy (White, 7 Features):", mean(wht_accuracies), "\n")
cat("Standard Deviation of Testing Accuracy:", sd(wht_accuracies), "\n")
#Gabi's attempt for Black ppl 2 feature model-----------
blk_results2 <- list()
# train 1000 times on 80/20 test/train split
for (i in 1:1000) {
# Split the data into training and testing sets
blk_split <- rsample::initial_split(blk_broward, prop = 0.8)
blk_train <- training(blk_split)
blk_test <- testing(blk_split)
# Define 7 feature logistic regression formula with only black defendants
blk_form2 <- as.formula("two_year_recid ~ age + priors_count")
blk_model2 <- glm(blk_form2, data = blk_train, family = binomial)
# Run model on test data
predictions <- predict(blk_model2, newdata = blk_test, type = "response")
predicted_labels <- ifelse(predictions > 0.5, 1, 0)
# Store model & results
blk_results2[[i]] <- list(model = blk_model2, accuracy = mean(predicted_labels == blk_test$two_year_recid))
}
# Extract relevant information from the results
blk_accuracies2 <- sapply(blk_results2, function(x) x$accuracy)
# Print the summary of the accuracies
cat("Mean Testing Accuracy (Black, 7 Features):", mean(blk_accuracies2), "\n")
cat("Standard Deviation of Testing Accuracy:", sd(blk_accuracies2), "\n")
#Gabi's attempt for Black ppl 2 feature model------------------------
wht_results2 <- list()
# train 1000 times on 80/20 test/train split
for (i in 1:1000) {
# Split the data into training and testing sets
wht_split <- rsample::initial_split(wht_broward, prop = 0.8)
wht_train <- training(wht_split)
wht_test <- testing(wht_split)
# Define 7 feature logistic regression formula with only black defendants
wht_form2 <- as.formula("two_year_recid ~ age + priors_count")
wht_model2 <- glm(wht_form2, data = wht_train, family = binomial)
# Run model on test data
predictions <- predict(wht_model2, newdata = wht_test, type = "response")
predicted_labels <- ifelse(predictions > 0.5, 1, 0)
# Store model & results
wht_results2[[i]] <- list(model = wht_model2, accuracy = mean(predicted_labels == wht_test$two_year_recid))
}
# Extract relevant information from the results
wht_accuracies2 <- sapply(wht_results2, function(x) x$accuracy)
# Print the summary of the accuracies
cat("Mean Testing Accuracy (White, 2 Features):", mean(wht_accuracies2), "\n")
cat("Standard Deviation of Testing Accuracy:", sd(wht_accuracies2), "\n")
blk_results2
# Extract relevant information from the results
blk_accuracies2 <- sapply(blk_results2, function(x) x$accuracy)
# Print the summary of the accuracies
accuracy_blk_2 <- mean(blk_accuracies2)
# Print the summary of the accuracies
accuracy_wht_2 <- mean(wht_accuracies2)
# Print the summary of the accuracies
accuracy_wht_7 <- mean(wht_accuracies)
# Print the summary of the accuracies
accuracy_blk_7 <- mean(blk_accuracies)
accuracy_blk_7
accuracy_wht_7
accuracy_blk_2
accuracy_wht_2
#CONFIDENCE INTERVALS
confidence_interval <- function(blk_accuracies2, 0.95) {
#CONFIDENCE INTERVALS
confidence_interval <- function(vector, interval) {
# Standard deviation of sample
vec_sd <- sd(vector)
# Sample size
n <- length(vector)
# Mean of sample
vec_mean <- mean(vector)
# Error according to t distribution
error <- qt((interval + 1)/2, df = n - 1) * vec_sd / sqrt(n)
# Confidence interval as a vector
result <- c("lower" = vec_mean - error, "upper" = vec_mean + error)
return(result)
}
confidence_interval(blk_accuracies, 0.95)
confidence_interval(accuracies_7, 0.95)
confidence_interval(accuracies_2, 0.95)
confidence_interval(blk_accuracies, 0.95)
confidence_interval(blk_accuracies2, 0.95)
confidence_interval(wht_accuracies, 0.95)
confidence_interval(wht_accuracies2, 0.95)
CI_t <-  function (x, ci = 0.95)
{
`%>%` <- magrittr::`%>%`
Margin_Error <- qt(ci + (1 - ci)/2, df = length(x) - 1) * sd(x)/sqrt(length(x))
df_out <- data.frame(  sample_size=length(x), Mean=mean(x), sd=sd(x),
Margin_Error=Margin_Error,
'CI lower limit'=(mean(x) - Margin_Error),
'CI Upper limit'=(mean(x) + Margin_Error)) %>%
tidyr::pivot_longer(names_to = "Measurements", values_to ="values", 1:6 )
return(df_out)
}
CI_t(accuracies_2, ci = 0.95)
#7 feature model AUC ROC
# Initialize variables to store results
conf_matrix7 <- matrix(0, nrow = 2, ncol = 2)
model_results <- list()
roc_auc_values <- numeric(1000)  # To store AUC-ROC values
# Train 1000 times on 80/20 test/train split
for (i in 1:1000) {
# ... (same as your existing code)
# Calculate ROC curve
roc_curve <- roc(broward_test$two_year_recid, predictions)
# Store AUC-ROC value
roc_auc_values[i] <- auc(roc_curve)
# Update overall confusion matrix
conf_matrix7 <- conf_matrix7 + conf_matrix_iteration
# Store model & results
model_results[[i]] <- list(model = model_7, accuracy = mean(predicted_labels == broward_test$two_year_recid))
}
# Calculate ROC curve
roc_curve <- roc(broward_test$two_year_recid, predictions)
roc_curve <- roc(broward_test$two_year_recid, predictions)
# train 1000 times on 80/20 test/train split
for (i in 1:1000) {
# Split the data into training and testing sets
broward_split <- rsample::initial_split(broward_clean, prop = 0.8)
broward_train <- training(broward_split)
broward_test <- testing(broward_split)
# Define 7 feature logistic regression formula
form_7 <- as.formula("two_year_recid ~ age + sex + juv_misd_count + juv_fel_count + priors_count + charge_id + charge_degree")
model_7 <- glm(form_7, data = broward_train, family = binomial)
# Run model on test data
predictions <- predict(model_7, newdata = broward_test, type = "response")
predicted_labels <- ifelse(predictions > 0.5, 1, 0)
# Calculate confusion matrix
conf_matrix_iteration <- table(Actual = broward_test$two_year_recid, Predicted = predicted_labels)
# Update overall confusion matrix
conf_matrix7 <- conf_matrix7 + conf_matrix_iteration
#ROC Curve
roc_curve <- roc(broward_test$two_year_recid, predictions)
# Store AUC-ROC value
roc_auc_values[i] <- auc(roc_curve)
# Store model & results
model_results[[i]] <- list(model = model_7, accuracy = mean(predicted_labels == broward_test$two_year_recid))
}
precision_table7 <- precision_df |>
gt() |>
tab_spanner(
label = "7 Feature Classifier Prediction",
columns = c("Predicted_No", "Predicted_Yes")
) |>
fmt_number(
columns = vars(Predicted_No, Predicted_Yes),
decimals = 0) |>
tab_header(
title = "7 Feature Classifier Prediction of Recidivism vs Actual Recidivism",
subtitle = "Results from training 1000 times on defendant data with features age, sex juvenile misdemeanor count, juvenile felony count, priors count, charge type, & charge degree: 67.47% overall precision",
)
precision_table7
accuracy_blk_7
accuracy_wht_7
accuracy_blk_2
accuracy_wht_2
accuracy_overall
